# 实验 {#exp}

实验的基本任务包括描述现象、推断机理与预测验证。描述性实验或者说观察研究也是需要设计才能回答科学问题的；机理或验证实验则必须通过随机化与控制变量来设计。当科学发展到实验科学年代，统计学就要去解决刻意观察获得规律的方法。这里面随机化是一个核心观念，用来确保除了你关心的变量，其余的都能随机或符合某个分布。1874在《科学原则》这本书里首次提到了控制变量法，一次测一个。但在统计学大放异彩的20世纪，Fisher 认为一次回答一个问题是错的，因为自然问题从来都是复杂的不能只回答一个，提出了加性模型。这里统计学要为复杂现象提供合理的设计工具，时至今日，在数据概念满天飞的时代数据收集似乎不是问题，很多人就会说更重要的是提出问题。这倒没错，但如果没有统计学思维加持，很多问题是无法对应实际数据的，如果设计不当或有偏，拿到的现象就会产生误导。

George Box 在《Statistics for experimenters》的第一章里没有扯什么随机化、均匀性，而是聊了下认识论。开篇第一句就是“知识就是力量”，解决问题实际就是一个认识模型演进的过程。具体来说是一个归纳-演绎不断往复的过程，数据起了中介作用。例如下面这个认识过程：

（模型）每天都一样

（演绎）今天车会停在原位

（数据）车不在

（归纳）有人偷车

（模型）车丢了

（演绎）车不在原位

（数据）车又回来了

（归纳）有人偷了车还回来了

具体到实验，这个过程就成了（模型）想法 ->（演绎）实验设计 ->（数据）结果分析 ->（归纳）结论或新想法。这大概是实验设计能上升到的最高理论高度了。不过，实验涉及的测量与分析方法对于科研提供经验事实非常重要，经常扮演理论的试金石，现代科研离不开实验结果支撑，且向自动化、模块化、定量化发展。实验学科的科研人员不必对工程技术细节完全掌握，但必须清楚其中测量原理与简单的故障诊断，否则实验就会黑箱化。

## 思想实验

这是科学实验里非常特殊的一种，通过预设场景进行推演，得到结论。常见于物理学，但其他学科也[有](https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3%E5%AF%A6%E9%A9%97)。

## 仿真实验

相比于思想实验纯粹的逻辑规律演绎，仿真实验则更多用于系统考察现象或考察系统特性。仿真实验的基础在于预定义个体或部分的属性与行为规则，然后在整体层面上观察现象。仿真实验的科研应用场景有两个：计算机辅助设计（CAD）与个体为本模型（ABM），前者更多用在工科研究中，例如工程力学上会通过建筑物建模来考察承重建材选择等问题，特别是没有解析解需要数值求解的问题，因为是计算机模拟，可以采集很多极端条件下系统承载参数；后者则更多出现在复杂性科学研究中，特别是博弈论与系统动力学考察，例如研究生态学种群变化规律就可以通过定义捕食规则与寿命，然后初始化一条食物链来研究系统的物质能量流动，例如生物圈二号。

仿真实验的三大基础是科学计算、机理与统计学。科学计算能力提升可以同时考察更多参数，更好模拟真实场景。新机理的提出与验证是多数仿真实验的目的，而已知机理的仿真则是模型的基础。统计学是仿真实验得到结论的工具，统计模拟可以帮助在未知规律的前提下展示提炼规律。相应的，仿真实验设计也要对科学问题的可计算性、原理与统计观测指标有清晰定义。

当前仿真实验的大趋势是虚拟化，越来越多的实验现在可以在计算机上模拟，小到分子动力学过程，大到谣言的网络传播机制都可以建模仿真。有机理则预设机理，机理不清楚就通过统计规律来揭示。越是接近真实的模拟，计算量与未知参量就越多，对经验公式与观察反馈也越高，甚至很多人认为人类就活在仿真程序里。

## 观察实验

观察实验是科学实验早期的主要形式，用无干涉观察来归纳总结规律，现在在社会科学或涉及人与伦理问题的科研中依然是主要方式。观察实验也需要设计，在流行病学研究中，随机对照实验是最理想的但实际更多结论则是来自队列研究或断面研究。究其原因在于很多控制手段存在伦理问题，只能通过调查追踪的方式来进行。当然，观察实验的科学问题侧重归纳性的规律总结，例如描述疾病在人群中的空间、时间分布或人群间属性例如年龄、性别、BMI、吸烟历史等的分布。为了观察数据可靠，就要有可靠的采样理论，在采样上或随机或均匀或分组布点，防止系统偏差。观察实验的难点在于观察数据不随机，这导致很多基于随机过程的统计推断无法展开甚至意识不到，观察实验的数据要很谨慎的纳入或排除可能的干扰因素，数据处理上就是对实际过程进行建模，用简化模型来控制影响因素，达到考察特定因素或指标变化规律的目的。

伴随组学或大数据技术的出现，现代科研也需要更先进的观察研究方法论。在组学或大数据研究中，实验更多侧重数据挖掘而非设计，很多时候甚至要通过额外的数据处理手段来矫正观察数据的系统误差。在这类研究中，实验不是基于假设来设计的，随机性很难保证，要通过设立自我对照或配对来挖掘现象背后的规律。此时实验设计的思维要延续到数据处理中，更多相关问题我们在下一章会有解释。

## 控制实验

与观察实验相对应的是控制实验，在控制实验的语境下，除了需要考察的过程或因素外所有其他因素都做随机化处理。最常见的控制变量法就是一组实验只考察一个因素的影响。当然，如果打算同时考察多因素多水平的影响，可以理解为一个寻优问题，翻译成数学语言就是 $y = f(x)$ 中，y代表了你期望最优的东西，x代表了会对y产生影响的自变量，如果你的问题可以抽象成 $y = f(x)$，那就可以通过构建模型来解决。实验设计主要关心的是方差分析这个视角，简单说就是y的变异可以拆分成不同x之间的独立变异或交互作用的线性组合。通过方差分析可以找到对y影响最大的x或所有x的影响方式，了解了影响方式，寻优什么的就比较简单了。不过此时的难点在于如何定义一个综合指标来描述多因素水平下整体的表现。

一般而言，想找出多因素的最优组合，第一步是要确定哪些因素重要而哪些因素不重要，这是PB设计的应用场景。在不考虑交互作用的前提下，通过PB设计的表头进行两水平试验，然后进行方差分析并可视化就可以筛选出重要因素了。PB设计的试验次数一定是4的倍数，而且最大适合因子数会比试验次数少1。打个比方，我打算找出9个因素中哪个影响目标最大，那么我的试验次数至少选12，下面是个演示，这里我们使用 `FrF2`包：

```{r pb}
suppressMessages(library(FrF2))
pb(12,nfactors = 9)
```

这里面1与-1分别代表两个水平，当然试验设计牵扯到分辨率问题，可以理解为对该试验设计的评价，分辨率高，能区分的影响就更细致，可以用`FrF2`包中的`GR`函数来计算。需要注意的是，`FrF2`包也可以用 `FrF2` 函数来进行两水平试验设计，这里是分辨率高时是可以考察交互作用的。

那么当你收集了数据，该如何分析呢？`FrF2`包实际继承了 `DoE.base` 包的S3对象类型，你只需要用 `add.response` 增加你的试验结果到设计出的S3对象上，然后就可以用方差分析或线性回归进行分析了。结果同样可以用`MEPlot`函数来进行可视化。当然，也可以用`halfnormal`函数来评价因子影响。

```{r pba}
plan.annotated <- pb(12,nfactors = 9)
response <- c(35, 36, 38, 39, 37, 36, 39, 37, 41, 32, 42, 37)
plan.resp <- add.response(plan.annotated, response)
MEPlot(plan.resp, abbrev = 5, cex.xax = 1.6, cex.main = 2)
summary(lm(plan.resp))
```

在这里PB设计实际上是一种预选法，如果结果显示某些变量影响显著，那么事实上就可以针对这些变量进行进一步的精细筛选，其余的变量可以直接固定为一个水平进行进一步设计。PB法在工业届用的比较多，但你应该想到了，如果只是进行变量选择，为啥不用随机森林或lasso？其实都可以，但这些方法不是设计而更多是数据分析通用方法，设计上除了最重要的随机性也是要考虑各因子贡献或者说重复数尽量平衡些的，否则会过分偏重某个因子，或者干脆配对或组成区组。像这样不做预设去设计对各个因子都公平，如果有预设或现实条件不允许，也可以裂区设计。

当选出重要因素时，下一步常见是正交试验或响应面分析，用来优选参数。正交表这玩意我在书中没找到，文献里用得多的也是亚洲人，老外统一用析因试验来进行考察。其实正交表的设计原理就是用尽量少的步骤遍历掉因子空间，这样进行一定次数试验就可以发现最优组合。R中的实现基本都在`DoE.base` 包里，这个包内置了一堆可以直接调用的正交表，可以根据需求进行查询。例如我有6个因素，水平数分别是2，3，3，2，2，6，然后我只打算做不超过54次试验，这时可以直接调用`show.oas`函数进行查询，给出的正交表随意选一个就可以继续。

```{r}
show.oas(nruns = c(0, 54), nlevels = c(2, 3, 3, 2, 2, 6), showmetrics = TRUE)
```

这里我们选分辨率略高的`L36.2.10.3.8.6.1`，从名字上看，这是一个36次试验表，可以包含10个两水平，8个三水平与1个六水平因子，这也是唯一一个分辨率高于3，可以排除交互作用的设计方法。这里我反复提到分辨率，实际上就是一种考察试验设计合理性的指标，分辨率3一般指只能区分没有交互作用的各因子贡献差异，高于3就可以区分一定的因子交互作用，可以用`GR`去计算一个广义分辨率并用`oa.design`来进一步优化这个设计，因为其实符合正交表只是众多选择的一个子集，不过根据优化方法的不同，优化时间也不太一样。

```{r}
oa.design(L36.2.10.3.8.6.1, nlevels = c(2, 3, 3, 2, 2, 6), columns = "min34")
```

使用这个函数你就不用费力去套正交表了，直接可以用输出的设计方案，记得要说明你的分辨率优化方案。如果你坚持套正交表，一定要理解如何去套，因为正交表的排列是很讲究的，特别是你要考虑交互作用的影响。如果一个表最多14个因子而你就设计了14个因子，那么分辨率不会超过3。正交设计的分析与前面PB设计是一致的，都是沿用添加响应，然后方差分析或线性分析随意来就是了，`DoE.base` 包为`design`这个对象类型设置了`lm`与`aov`方法。

在进行数据分析时，有时会遇到方差分析与线性回归的区别问题，打比方你用线性回归来做分析，会有审稿人问你lack of fit检验有没有做。这个检验实质上也是个F检验，用来衡量线性模型之外残差里分组变异与纯误差变异的比值，如果分组变异还是比较大，那么线性假设可能就不合理。

不过，目前实验设计结果分析更精细的会用响应面分析。顾名思义，响应面有点梯度下降迭代寻优的意思，而且如果是曲面通常考虑了二阶甚至更高阶的交互作用。在R中的实现是通过 `rsm` 包来进行的，这个包也是囊括了设计与分析两个部分，设计部分也有常见的 Box-Wilson Central Composite Designs 与Box-Behnken designs，分析部分自然还是基于`lm`的。同样，对于CCD设计，也提供了`ccd.pick`来选择好的设计，这里好自然意味着一些表征设计均衡的统计量。因为`rsm` 包小品文写的很清楚了，我就略过演示了。如果你面临多响应同步优化问题，那么`desirability`包考虑一下有没有，这个包其实是定义了一个多响应的联合满意度作为目标统计量，然后用响应面分析进行寻优，对于组学研究是有启发的。另外说个小八卦，狭义正交表也就是田口设计其实最初是两响应优化，只不过另一个响应是无法控制的噪音，田口搞了个信噪比来解决问题，熟悉了这套统计量构建策略，你也应该能做到根据实际情况构建指标体系。

其实实验设计分析是可以用所有符合$y = f(x)$的模型来操作的，说白了就是参数寻优。但试验设计更独特的点就在设计上，更广义地讲，A/B测试等纯计算试验也可以套用试验设计原理，这里要区分清楚设计与分析，设计不合理，分析会很头痛。如果再扩展些，观察研究的试验设计相比控制实验更关注配对或策略抽样。总之试验设计并不是什么水晶球，其原则从来都很清楚，只是后来流派出的太多，术语也越来越晦涩。然后你就会在网上看到哪个软件能做哪个分析的讨论了，其实这情况在工科可能更严重些，例如混料配比的[三角坐标系设计](https://support.minitab.com/zh-cn/minitab/18/help-and-how-to/modeling-statistics/doe/supporting-topics/mixture-designs/what-is-a-mixture-design/)就完全是另一套，不过万变不离其宗，说白了还是个响应面分析。

所有的控制实验都要有对照组，且要根据实际需求设定不同种类的对照，例如阳性对照、阴性对照与空白对照等。对照组可能是反应测量精度的，也可能是为现象的描述提供基线数据。针对基线的对照设计要明白现实中的基线并不是完全随机的，或者说随机过程就可能产生一些现象规律而不是完全无现象，忽视这一点可能会误把偶然事件当成新规律，要克服认知上的错觉，从不同独立维度的验证或对基线的模拟是一定要做的。

## 因素选择

对于特定科学问题，从哪里入手设计实验是需要谨慎思考的。我们的研究对象是单一物理实体，其影响因素要优先考虑其环境因素，基本出发点就是最基本的物理指标：长度，质量，时间，电流，热力学温度，物质的量和发光强度。所有的实验影响因素都应是这些物理指标组合而来，单位可以还原到这些物理指标的组合。描述因素影响上最基本的就是热力学与动力学描述。热力学描述可理解为现象稳态时的各种参数描述而动力学则关注现象在时间尺度上的参数变化。例如食盐在不同温度下溶解度就是其热力学描述，而固定温度下溶解过程中固态与溶解态的比例就是动力学描述。热力学与动力学过程涉及很多其他物理参数，但最常用的就是浓度或含量，特别是在不同温度、pH值与离子强度等环境参数条件下的热力学表现与动力学趋势。很多材料类论文的核心就是去表征新材料的各种属性参数，如果某项属性参数特别好，那么这种材料的现实意义也就特别高。

如果你研究的不是单一物质而是混合物，除了考虑热力学与动力学过程外还要考察混合物组分配比或组合方式对性质的影响。混合物可以是分子层面的，也可以是个体层面的，例如心理学或生态学上研究某些现象时不会只依赖单一个体的表现，但个体间组织方式也是影响某些心理现象的，例如是否来自同一家庭，是否是上下级关系等。此时在因素选择上要充分考虑哪些是不变的，哪些是可变的，或者说研究对象是否是均质的，否则不论是在实验设计还是数据分析阶段都要对相关因素进行控制。

同样的道理适用于对现象的研究。某个现象可能是复杂的个体关系与环境影响的结果，要搞清楚哪些是重要影响因素，哪些是可控制的，哪些是可是事后建模消除影响的。此时建议列个清单或者脑图，从现象内部到外部列出来所有因素，有些因素其实并不互相独立，此时要考虑如何建模消除掉非独立因素或整合为一个独立因素。

因素选好后就要考虑如果因素是分类的，那么不同分类的样本数能否平衡；如果因素是连续的，那么这个连续尺度是否在实际环境中存在。在更多情况下，控制实验的因素水平是事先选好的，这个水平可以推向极端来考察理论问题，但考虑实验的经济性与可重复性要优先考虑室温人居环境下存在的水平。例如考察污染物的对微生物的生态影响，其污染水平要跟环境中实际存在的污染水平相对应，否则做出的结果很难有实际意义。此外，现代技术进步使多维度同时考察变得可能，因素数也会变得越来越多，越来越复杂。此时要特别注意冗余分析，排除掉无关因素或实质等同的因素，避循环论证与被分析方法牵着鼻子走。

当然，前面所述思考方式是从头思考的，现代科研更多是建立在别人的工作上的，如果你并不是做的开创性工作，那么阅读类似文章对比论文结构可能是更实际的因素选择方式。这里还是要强调从头思考的重要性，因为这样可能发现前人所未想到的研究方向，而且一定也要去读别人的论文思考他们的思路，完全的闭门造车容易滑向民科的无底洞。

## 效应指标

实验设计要有明确的效应指标，可以是定性的，但最好是定量的。效应指标要简明直观去主观化，例如描述一种气味可以用文字，也可以用形成气味的物质比例，前者是一种感受，会带有主观差异，后者则是一种客观描述。各学科在发展中产生了很多专有指标，用来描述一些条件下有实际意义的过程与结果。现代指标体系很大程度是分析测量技术决定的，测量仪器给出的指标在对应研究领域内是相对通用的，从业人员要明白测量原理及故障应对方法，否则测量上如果存在问题就无法溯源与修正。

实验指标的构建可以是直接来自于测量本身，也可以是收取相关指标后续定义算法来计算。但无论如何测量数值都要有明确的物理意义，其背后也要有现实意义支撑，否则实验结果无法有效讨论。此外，指标还要保证信度与效度。所谓信度就是可靠性，也就是给出重现性好不确定性低的信号而不是随机信号，而效度要求则要保证指标可以反应所探索的问题。用体重秤来举例，高信度低效度的体重秤会给出一个稳定的数值，但这个数值却可能不是体重或总是系统高一个数，而低信度高效度的体重秤会给出一堆数值，虽然平均后是体重但测一次一个样，重现性不好。好的指标本身是依赖客观物理量但却能反应某个科学问题，例如水的总有机碳含量就可以指示或代表可燃成分的含量，同时可以用燃烧后测定质量的方式来得到高重现性的数值。

关于信度的考察要通过不确定性分析或信噪比分析。所有指标都有不确定度，一部分不确定度来自测量中引入的误差，还有一部分则可能来自指标本身组成就不稳定，例如心理学里对性格的定义。很多科学问题需要高分辨率数据，此时如果分析方法或指标噪音过多，那么也无法说明一些规律。

关于效度的考察要通过敏感度分析，看要指示的指标是否对想考察的问题能准确指示，这个时候一般会牵扯到“黄金标准”的概念。所谓黄金标准，就是行业内使用时间比较长，认可度最高的指标体系。新的指标要想说明优势，要去考察其相对黄金标准是否更好。打比方我们用卫星图像数据来对应空气质量，那么首先要用实地监测数据这种传统但可靠的方法来验证结果是否可靠，否则也许图像数据能给出很多数值，但完全偏离实测数据就没办法用。

现代科研经常需要定义或使用一些综合指标来简化指示某些复杂现象过程，例如空气质量指数。综合指标的设计要用到层级结构与加权，这些经验信息要么来自于理论，要么来自于现状调查，但要做到其确实可以指示量化复杂现象或过程。此外，综合指标要有能力分拆为独立不相干的子指标来进行深入的机理讨论，例如空气质量指数的基础就是几种污染物的实测数据。

总之，现代科研不排斥新的指标，新的指标也为描述新的现象与机理提供了途径，但新指标的构建一定要考虑信度与效度，否则实验结果或者会因为误差太大不能准确描述现象，或者根本就没有说明现象。

## 采样与样品预处理

现实科研的样品可能来自工业化生产，也可能来自自然界。样品收集与预处理不但是很多后续分析的必然步骤，也是最容易被忽视的误差来源。如同统计采样一样，现实样品采样要符合代表性与随机性且要根据想看到效应的大小预设样本量。真实采样中几乎一定会遇到各种意外，需要保证采样信息的完整记录，包括但不限于采样时间、地点、采样人、样品名称、样本储运要求与其他意外信息的备注。样品采集后应尽快分析，减少储运带来的不确定性，储存条件或者是低温或者是保持样品原有环境。不过，现代采样技术的一大趋势就是原位实时采样甚至是依赖物联网传感器的实时监测，这样的采样尤其需要事先设计好位置与校准流程，保证数据质量。

样品预处理是现代样品分析的重要步骤，要设置好过程空白等流程来进行分析过程的质量保证与质量控制。样品预处理一方面是为了让样品均质化稳定化，另一方面则是为分析过程服务的，例如减少对分析仪器的污染。样品预处理的趋势是自动化，不过要事先根据研究目的来评估已有自动化流程是否会影响或系统误差。

然而，采样与样品预处理在很多时候由于考察问题的新颖性是做不到机器取代人工的，依然属于劳动密集型工作，适度的编程会有助于过程的自动化但现实问题的复杂需要人的干涉，特别是探索阶段。请做好文字记录或多媒体原始记录，这样更容易查找问题。

## 预实验

如果条件允许，所有正式实验前可以进行预实验。预实验经常用来评价实验方法是否可靠，重复性如何，特别是在该实验从未操作过的时候用来熟悉流程。预实验的研究对象很多时候不是真实样品而是标准参考物质或基质空白。有时预实验也会在小样本上进行验证假设，如果有现象，则可以进行正式实验设计，如果没有则可以记录后中止实验。

对于新手而言，预实验也是很好的训练机会，用来对全流程形成操作层面概念。越多的试错就越好保证正式实验的数据质量，因此预实验的打磨对于所有实验科学科研人员都是必修课。
