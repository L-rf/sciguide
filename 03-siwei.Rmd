# 思维工具篇 {#thought}

## 科学思维

### 规律的失效

科学靠谱很大程度是规律性进行的保障，规律保证了可预测性，但其实很多规律恰恰说明在很多地方没有规律。

### 哈森奇效应

### 观察研究的敌人-反馈

## 模型思维

模型思维是一种一对多的思维方法，从相似的事实中提炼出逻辑规律，用规律来指导认知世界，这种思维的优势在于逻辑或者说理性起决策主导参考作用。当一个模型出错时，我们可以运用其他模型来研究某个事实，因为所有的模型都存在简化，所以知道模型越多越有利于理解世界里发生的事。模型都有自己的准确度与适用范围，一般而言，高准确度的模型适用范围比较精确且会形式化为公式，而低准确度模型类似万金油，无所不包但含义模糊。模型化思考是首先抽离出变量，然后确定变量间关系，最后运用逻辑推理来进行思考的过程。模型终点可能是循环的、平衡的、随机的与不确定的，要用概率角度而不是决定论去看结果。

模型主要有两种，一种是基于公式的，另一种则是基于单元的仿真模型，前者需要你清楚的了解模型机理，后者则需要假定单元的活动空间与行为方式，然后通过模型运转来了解整体变化。

### 可编程

可编程是计算机科学的核心概念，当一件事可编程时，我们就可以设计出相对的硬件与软件来自动化这个过程。对于科研人员，硬件方面一般较少涉及，软件编程却是日趋日常化。因此，我们有必要了解编程语言的一些基本概念与思想。

程序是编程的结果，一般包含一条或一组执行运算的指令，这里运算并不仅仅指数学运算，也包括所有可通过电子电路完成的运算。要实现一次运算，我们至少需要输入值、运算与输出值。运算至少要能实现数值运算、顺序执行、条件执行与循环。因此，如果你打算进行编程，你就需要通过计算机语言让计算机知道输入输出与运算过程。

计算机语言不同于日常交流的自然语言（虽然可以处理自然语言），其核心特质在于描述上的准确性。不论操作符、数据类型还是函数定义，不同的计算机语言都有自己的规范来确保人要求的抽象化与机器能听懂人的要求之间达到平衡。底层语言例如汇编语言机器非常容易懂，但人不容易将需求转化为汇编语言。高级语言需要编译成底层语言来执行，不过人相对容易将需求进行编程。这个编译过程会损失效率，所以一般学习的语言越容易，效率与准确性往往会受影响。

科研里一般用程序来处理数据，所以科研编程的语言选择往往是实现效率、处理方法与编程难度的平衡。一般来说，数据处理方法源于统计学知识，编程难度取决于学科现实问题的抽象模型而实现效率属于纯计算机科学问题，科研人员可根据自己知识背景进行选择。对于非计算机科学专业的科研人员，建议关注学科内主流编程语言，否则后期会有很多交流上的困难，或者一步到位实现程序的应用化，让用户在少量编程知识的背景下就可以应用。

学习编程语言一般首先要掌握变量类型、赋值、表达式语法、保留词、注释等基本概念，然后就是大量的交互式案例训练来熟悉用法。编程语言一般会自带 REPL (Read–Eval–Print Loop；读取-执行-打印循环) 程序，在这个程序下会识别该编程语言的语法与操作符，互动地输入输出数据与结果。在编写程序代码时，最基础的要求是搞清楚编程语言的优先级，例如括号>指数>乘除法>加减法，一般执行顺序是从左到右。

另一种使用编程语言的方式是通过独立程序实现特定功能来完成的，运行程序可以直接得到输出，人机互动是在应用层上的。 REPL 方式其实比较符合数据分析的需求，后一种方式则反映了软件工程，涉及了程序的设计、构架与封装。目前科研应用中侧重交互式数据分析而业界则更看重程序编写与功能实现，前者存在试错且探索为主，后者则更侧重目标。这个区别专业程序员或软件工程师经常体会不到，觉得用 REPL 的科研数据分析是初学者，不能算编程。但其实科研数据分析的核心就是计算与需求的互动，REPL 只是其中一种，将需求从REPL过度成程序也是很重要。

也就是说，交互式与独立程序之间往往还有一个中间态，可以是脚本，也可以是自定义函数。一段代码一般是以输入为始，以输出为终，中间有函数来处理数据。在固定模式的数据处理中，一个函数的输出往往可以是另一个函数的输入，将输入输出代码按顺序、条件、循环排好就可以产生一个新的组合函数。事实上很多高级语言就在逻辑上抽象出一些常用函数来方便程序员直接调用。

同时，为了实现具体的功能，函数的输入除了数据外还有一些参数，有些是经验值，有些则可能要来自于功能本身定义。在输出上，有些函数的输出可以返回数值，有的可能就是打印到屏幕上就结束了，根据实际需求来。此外，多数语言的函数内部变量是只在内部可生产或可调用的，内部没有就可能从当前环境里找，最好不要设计这样的程序。函数或脚本对数据分析最大的意义在于减少重复工作与理清分析思路，对于软件工程则属于搭建工程部件，无论如何都是件功在当代利在千秋的事。

如果程序设计有问题，编程语言也会有对应 debug 的过程，大多数情况下是编程者的需求与机器的执行不对应导致，可以从这里入手思考修改代码。常见的错误包括但不限于语法错误、语义错误与例外。

下面重点讨论下编程思维中一些常见现象与术语，侧重理解并最好通过联系来强化理解。

- 条件分支：函数中出现需要对数据子分类进行不同运算时的设计，不同子分类用不同条件语句进行逻辑判断，例如数值求绝对值要先判断正负。

- 循环：同样的操作要对不同的可索引或满足特定条件的数据进行运算，这种情况要设计循环结构，例如按数据行/列求值。有些循环循环数是知道的，有些则要对数据运行结果进行判断，满足特定条件时可跳出或继续循环。

- 递归：比较特殊的条件与循环结构，当数据不满足某条件时就执行函数本身直到满足条件，例如求解斐波那契数列之和就可以设计递归结构循环执行本身直到数据可计算的起点。递归的效率一般不高，但递归结构有助于简化思考问题的步骤。

- 正则表达式：正则表达式是字符串处理时常用的模式识别工具，灵活使用正则表达式与条件分支可以有效处理真实数据中的混杂，强烈推荐[学习](https://zh.wikipedia.org/zh-hans/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F)掌握。

- 数据结构：通常不同数据按照实际需求会有不同的格式，不同格式的数据处理方式会不一样，一般函数都会先验证数据结构，如果不能处理则返回错误。

- 数据表：常见的数据处理格式，一般不同行表示不同样品，不同列表示不同样品属性且数据类型一致，数据值可以是数值、字符或逻辑值但不能是数据表。由于数据处理算法大都基于数据表开发，这类格式数据比较容易找到现成的算法函数/库/扩展包来进行处理。

- 字典：很多程序语言支持字典，字典是一种对应关系，字典中的元素是键值-数值对，通过键值索引数值，也可以反查。数据表中搜索元素是按照数值索引顺序索引的，字典则可以用哈希表快速索引。字典可以在编程中用来构建基于输入的数据库，方便进一步查询。

- 列表：列表属于数据表与字典的泛化，列表元素可以是数据表或列表，因此列表的数据结构不是平行的而是具备层级，有的元素可以进一步展开。列表常用来表示一组关联概念且可以数值索引，例如在回归分析的返回值中，就会包括拟合值、回归系数、残差等数据表或数值。

- 类型：通常列表可被定义成一种新通用类型，算法可基于这个类型进行开发或泛化，例如当你调用画图程序时，其程序会首先判断你输入数据的类型，如果有对应方法则直接调用，没有则用通用方法或返回错误。有些语言中列表是不能直接操作的，这样设计就是为了防止类型不兼容而强制定义格式。

其他一些概念例如并行运算、云计算、单元测试、集成测试、GPU加速、功能模块化、环境容器化、接口调用、功能移植、数据库检索、前端设计、数据加密、移动端兼容等都很有了解的必要，但这是建立在牢靠的基础上的。一个简单的判断标准就是根据你的需求你会觉得存在某种设计，然后一搜索发现果然有这样的领域，从需求出发回到需求中去是编程思维的要诀，不要在屠龙之术上花费太多时间。

- [参考资料](https://benlauwens.github.io/ThinkJulia.jl/latest/book.html)

### 个体整体模型

个体行为在群体中有两种形态，一种是同群效应，也就是被群体同化，细分也有两种，一种是直接服从整体，另一种是在周围环境压力达到自己设定时被同化，例如起立鼓掌模型；另一种则是物以类聚，也就是只跟自己相似的人聚集，如果被群体排斥就离开，例如谢林模型，这里微观的动机不同于宏观的表现。这两种状态宏观上都会造成隔离，但形成原因差异很大，一个是入乡随俗，另一个是回归舒适区。存在引导群体行为的策略，入乡随俗的可以加强引导而回归舒适区的可以强调区别，传销的人两种方法是交替使用的。

当人聚到一起后，整体就会有自己的属性，系统的表现取决于环境、个体间关系与系统组织结构，与个体属性关系就不大了。单一行为的聚合模型可以考虑中心极限定理；单一规则的聚合模型可以考虑细胞自动机，此时已经有系统高层次动态了；个体的偏好聚合后就会出现系统高层次矛盾，例如博弈论、投票、群体非理性等。

个体行为都是有自己决策过程的，决策模型分为多准则决策与概率决策，前者可以定性分析，也可以打分定量分析，可以使用空间量表可视化多维选择。概率决策是构建在事件及其后续事件发生可能性基础上的，赋值后根据决策树反推不同选择下的期望结果。基于概率决策树可以对信息定价，推算在有无信息下的期望差就是信息的价值。

人的思维过程跟物理世界运行规则是不一样的，有严格按规则办事的，有看心情办事的行为模式，还有理性行动者。后者会不断按目标函数寻优，经济学里的理性人假设就是如此，但存在边际效用递减的情况，理性不意味自私，跟个人目标或价值认同符合，有时则需要考虑群体最优。行为模式的人会有风险厌恶、对未来不如现在看重的双曲贴现、思维惯性拒绝改变与容易受眼前事件影响等不符合理性的行为。按规则办事的人可以靠规则来预测，例如博弈论里的分析与随机选择，决策越简单越容易执行。真实世界的人三种思维模式都存在，不同场合不同组合。很多时候基于规则会经验可能是最符合现状的，既不会绝对理性，也不会过于随意，大概取个中间值。

规则模型里比较常见的是分类模型与线性模型。分类模型就是把相似的东西归到一类里去，分类越能捕捉群体里的差异，模型就会越符合现实，其实就是组内方差最小化与组间方差最大化的体现。线性模型则是通过构建拟合两个变量的线性关系来进行预测，通常优于专家表现。线性模型中，R方可以用来描述模型解释度，系数正负可以告诉你效应方向，系数的量级可以表现系数的重要程度，系数的p值可以告诉你出错的概率。现实数据可以拆分成不同线性阶段，这样非线性就可以线性考察。重要系数的筛选属于循证研究，首先构建模型，然后收集数据，然后确定重要变量，然后改变变量来看影响，进而找出影响大的变量。线性模型也存在局限，例如不能识别因果，对于反馈作用无法预测，例如早先设计ABS系统是因为车距过近容易出事故，但有了ABS后实际车距反而缩小了，因为人们把ABS的影响反馈到行为里去了。

除了线性模型外，非线性模型可以看成线性模型的组合，这样就会存在临界点，不过要区分指数模型，内在动因不同，临界点前后量化属性会发生变化。SIS模型（易感者感染易感者）、SIR模型（感染者终身免疫）、SIRS模型（治愈后暂时免疫）。扩散模型中两人接触后发生传染的概率等于传染率乘人群中患者比率与人群中健康人比例，再乘以人群中接触率。扩散过程不存在临界点，但会存在概率快速上升的阶段。SIS模型中存在治愈患者，治愈后不会患病，这样接触率感染率的乘积与治愈率进行比较就是基本传染数。当基本传染数大于1，疾病会流行，小于1，疾病无法流行，基本传染数决定是否是流行病。免疫过程会降低基本传染数，麻疹为15，疫苗比例超过14/15时才不会流行。当疫苗免疫率不够临界值时，不打疫苗风险很高，超过后就可以不打了。在传染病模型中，临界点就是基本传染数。临界点的测量可以通过多样性指数或熵来比较，多样性指数就是不同类型概率平方和的倒数，越高多样性越高。熵则是概率与概率对数的乘积和的负数（信息可加和并考虑概率），越高越混乱，需要信息越多。

解决实际问题也存在模型，例如爬坡法，启发式还有重组法，爬坡就是寻优，改变参数看那个方向好就继续，视角越宽越不容易局部最优。启发式可理解为随机猜想，利用经验或部分信息进行快速决策，例如试错或排除等方法。重组法就是集思广益，使用群体智慧。多样性对于创新是很重要的，团队组建需要注意。

事情的发展可以用马尔可夫模型来模拟，当状态有限且发生概率恒定时，事情就会进行状态改变直到收敛。概率转移矩阵就可以计算最终平衡时比例，因为是动态平衡，经常反线性直觉。这个过程跟初始状态无关，跟过程也无关，通过随机性达到平衡，但如果转移矩阵改变了，就可能不收敛了。另一个事物发展模型是李雅普诺夫函数，它存在一个最大值或最小值，在没达到时会不断逼近，平衡时会停止波动，可根据构建的模型来估计逼近所需要的周期并优化。行为没有外部性会最终平衡，考虑外部性会复杂或随机，这个模型依赖路径与初始条件来达成平衡，平衡点固定不随机。

文化差异也存在模型，文化是使群体生活与个人生活能进行的事物，国家文化差异客观存在，个体通过与他人协调与自己行为磨合形成，文化交汇会促进相似但不是一致。一致性会形成路径依赖与偏好加强，最后形成临界点。事物的发生靠技能也靠随机性，技能接近看的是运气。

### 仿真模型



## 统计思维

### 统计量

### 回归

### 概率

### 方差

### 因果推断

## 最优化思维

### 梯度下降

- EM 算法 https://www.nature.com/articles/nbt1406

### 动态规划

- 动态规划 https://www.nature.com/articles/nbt0704-909

## 估算法

### 费米估计

http://www.mathsisfun.com/numbers/estimation.html

http://teachersinstitute.yale.edu/nationalcurriculum/units/2008/5/08.05.06.x.html
